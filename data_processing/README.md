This repository includes the pipeline used for producing the results discussed in the manuscript "Multi-scale early spillover warnings for influenza A viruses" by Alfonsi T., Bernasconi A., Chiara M., and Ceri S.

Below, a list of the **use cases and related pipelines**:
- H1N1 08-09: `analyses/h1n1_08-09.ipynb`
- H5N1 08-09: `analyses/h5n1_2019-2025.ipynb`
- Sensitivity and specificity analysis: `analyses/sensitivity_specificity.ipynb`

This document is organized as follows:
- In the _Data Requirements_ section, we describe the operations for collecting and preparing the data before using the pipeline. The pipeline assumes you provde for each use case, a CSV file with the metadata attributes of GISAID and the CDS for each sequence.
- The _Software Requirements_ section lists the packages needed for running the pipeline.
- The section _Use of the Pipeline_ explains how to integrate your data into the pipeline. 


# Data Requirements

The software assumes that users can access the EpiFlu GISAID database after registration to the service.

### Data collection

Download metadata and FASTA sequences from GISAID with the following filters:

##### H1N1 
- Type A
- Subtype H1N1
- Host: Human, Swine
- Location: North America
- Collection date: from 2008-01-01  to 2010-03-07
- Collection date complete
- Required segments: HA
- Only complete segments


##### H5N1
- Type A
- Subtype H5N1
- Collection date: from 2019-01-01  to 2025-01-27
- Collection date complete
- Required segments: HA
- Only complete segments

### CDS annotation

We used the command line library "Augur" to align the sequences in the FASTA files. But any other alignment tool should work fine, as long as the output allows to retrieve the coding seqeunce of the HA protein. 

The following reference sequences were used in the process:
- NC_026433.1 Influenza A virus (A/California/07/2009(H1N1)) segment 4 hemagglutinin (HA) gene, complete cds
- AF144305.1 Influenza A virus (A/Goose/Guangdong/1/96(H5N1)) hemagglutinin (HA) gene, complete cds

### Data cleaning 

We require:
- each pair Isolate_ID,Isolate_Name to be unique;
- Submission_Date and Collection_Date to be entirely specified;
- each sequences to have length within 3% from the median value of the sequences in the H1N1 or H5N1 dataset respecitvely;
- the CDS of each sequence to be available, complete and with length multiple of 3; 


### Data format
The required data should be in tabular form, with one row for each sequence, one column for each metadata value and one column named "CDS" for the coding sequence. 
The first column of the table acts as a primary key and must be generated by the concatenation of Isolate_ID and Isolate_Name, separated by an underscore (e.g., EPI_ISL_01234_A/H1N1/New_York/9876)


### Geoapify API key

The H1N1 pipeline makes use of the Geoapify service for homogenizing the Location attribute in a programmmatic fashion. In order to use this service, users can register for free to the Geopaify service and retireve an API key. The key should be saved in the file `data/geoapify.key`.


# Software Requirements

The software dependencies of the pipeline can be easily installed within a conda environment by using the command `conda env create -f environment.yml`. This command requires the dependency manager "conda" to be already installed in the system. 

# Use of the pipeline

Once the data has been download and transformed as described in the Requirements section, it is suggested to collect metadata and coding sequences into a single file readable through the python library `pandas`, for example, a CSV file:

```python
import pandas as pd 

data = pd.read_csv(csv_file_path)
```

The pipeline is organized as a single jupyter notebook for each case (H5N1, H1N1 and sensitivity/specificity analysis). In order to use the pipeline, you need to provide the starting point, i.e. a `Data` class defined as follows:

```python
from utils.pipeline import Step

class Data(Step):
    def run(self):
        return {
            'output': data,
            'metadata_feature_names': [...],    # the list of metadata column names from your file
            'data_feature_names': ["CDS"]       
        }
```

You will find a placeholder declaration of `Data` at the start of each jupyter notebook. 

